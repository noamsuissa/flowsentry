{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import string\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364it [00:01, 316.87it/s]\n"
     ]
    }
   ],
   "source": [
    "BASE_DATA_DIR = Path(os.getenv(\"BASE_DATA_DIR\"))\n",
    "TARGET_DATA_DIR = Path(\"data\")\n",
    "\n",
    "#alphanumeric string for patient renaming\n",
    "alphabet = string.ascii_lowercase + string.digits\n",
    "patient_dict = {} #store patient name and id pairs\n",
    "random.seed(1)\n",
    "labels_df = pd.DataFrame(columns=['leak', 'location', 'severity']) # create a labels df with the correct columns\n",
    "\n",
    "for patient in tqdm(os.walk(BASE_DATA_DIR)):\n",
    "    if len(patient[2]) > 0: #only look at deepest directories which contain images\n",
    "        full_path = Path(patient[0])\n",
    "        angio_location = full_path.name\n",
    "        angio_date = full_path.parent.name\n",
    "        patient_name = full_path.parent.parent.name\n",
    "\n",
    "        patientcase_id = ''.join(random.choices(alphabet, k=8))\n",
    "        patient_dict[patientcase_id] = {\"patient_name\": patient_name, \"angio_date\": angio_date, \"angio_location\": angio_location}\n",
    "\n",
    "        for i, frame in enumerate(patient[2]):\n",
    "            new_img_name = f\"{patientcase_id}_frame_{str(int(i+1)).zfill(3)}.png\"\n",
    "            current_img_path = full_path / frame\n",
    "            save_path = TARGET_DATA_DIR / \"train\"\n",
    "            \n",
    "            # TODO: make sure all images are the same size (even num channels)\n",
    "            Image.open(current_img_path).save(save_path / new_img_name)\n",
    "            \n",
    "            # Create a new row with the frame name as the index\n",
    "            labels = pd.DataFrame({\"leak\": [np.nan], \"location\": [np.nan], \"severity\": [np.nan]}, index=[new_img_name.split(\".png\")[0]])\n",
    "            \n",
    "            # Concatenate the new row to the labels_df\n",
    "            labels_df = pd.concat([labels_df, labels])\n",
    "\n",
    "# Ensure the 'frame' is set as the index\n",
    "labels_df.index.name = 'caseid_frame'\n",
    "labels_df.to_csv(save_path / \"labels.csv\")\n",
    "\n",
    "#save the file metadata to the data directory\n",
    "patient_df = pd.DataFrame(patient_dict).transpose()\n",
    "patient_df.index.name = \"patientcase_id\"\n",
    "patient_df.to_csv(\"data/metadata.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
